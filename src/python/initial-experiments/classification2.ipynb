{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "mjnMRrkODJuk"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n"
      ],
      "metadata": {
        "id": "FzJqxgFiDU-X"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://drive.google.com/file/d/1Cj_gZFUmvegKICLQxSuPRk0QT5zvtPgK/view?usp=drive_link\n",
        "#https://drive.google.com/file/d/1HObEZNhDxOCCFcVnRQzW9y3w4nd_yiDx/view?usp=drive_link\n",
        "#https://drive.google.com/file/d/1ovu6KTPb8bc0h06A2nvy-kahAmecQjhy/view?usp=drive_link\n",
        "your_file_all = drive.CreateFile({'id':'1Cj_gZFUmvegKICLQxSuPRk0QT5zvtPgK'})\n",
        "your_file_ta = drive.CreateFile({'id':'1HObEZNhDxOCCFcVnRQzW9y3w4nd_yiDx'})\n",
        "your_file_oc = drive.CreateFile({'id':'1ovu6KTPb8bc0h06A2nvy-kahAmecQjhy'})"
      ],
      "metadata": {
        "id": "dWoopK4jDVHP"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "your_file_all.GetContentFile('bitcoin-all-on-chain-and-technical-indicators.csv')\n",
        "your_file_ta.GetContentFile('bitcoin-all-technical-indicators.csv')\n",
        "your_file_oc.GetContentFile('bitcoin-all-on-chain.csv')"
      ],
      "metadata": {
        "id": "JSXfj1ugDVMn"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Flatten\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import seaborn as sns\n",
        "import os\n",
        "import time\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "gKjw9oTgDVPP"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ta_df = pd.read_csv('bitcoin-all-technical-indicators.csv')\n",
        "ta_df['timestamp'] = pd.to_datetime(ta_df['timestamp'])\n",
        "ta_df.set_index('timestamp', inplace=True)\n",
        "#ta_df = ta_df.dropna()\n",
        "ta_df_returns = ta_df.pct_change()\n",
        "# Replace infinities with NaN\n",
        "ta_df_returns = ta_df_returns.replace([np.inf, -np.inf], np.nan)\n",
        "ta_df_returns.fillna(0, inplace=True)\n",
        "ta_df = add_target_to_dataframe(ta_df)\n",
        "\n",
        "oc_df = pd.read_csv('bitcoin-all-on-chain.csv')\n",
        "oc_df['timestamp'] = pd.to_datetime(oc_df['timestamp'])\n",
        "oc_df.set_index('timestamp', inplace=True)\n",
        "oc_df_returns = oc_df.pct_change()\n",
        "oc_df_returns = oc_df_returns.replace([np.inf, -np.inf], np.nan)\n",
        "oc_df_returns.fillna(0, inplace=True)\n",
        "oc_df = add_target_to_dataframe(oc_df)\n",
        "\n",
        "oc_ta_df = pd.read_csv('bitcoin-all-on-chain-and-technical-indicators.csv')\n",
        "oc_ta_df['timestamp'] = pd.to_datetime(oc_ta_df['timestamp'])\n",
        "oc_ta_df.set_index('timestamp', inplace=True)\n",
        "oc_ta_df_returns = oc_ta_df.pct_change()\n",
        "oc_ta_df_returns = oc_ta_df_returns.replace([np.inf, -np.inf], np.nan)\n",
        "oc_ta_df_returns.fillna(0, inplace=True)\n",
        "oc_ta_df = add_target_to_dataframe(oc_ta_df)\n",
        "\n",
        "price_only_df = ta_df[['price']]\n",
        "price_only_df_returns = price_only_df.pct_change()\n",
        "price_only_df_returns = price_only_df_returns.dropna()\n",
        "price_only_df = add_target_to_dataframe(price_only_df)"
      ],
      "metadata": {
        "id": "41vTgAyVDVRw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2347b6d4-b2fd-4f79-a22a-59ac7c6056fd"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "increase     1553\n",
            "decrease     1350\n",
            "no change      16\n",
            "Name: target, dtype: int64\n",
            "increase     1553\n",
            "decrease     1350\n",
            "no change      16\n",
            "Name: target, dtype: int64\n",
            "increase     1553\n",
            "decrease     1350\n",
            "no change      16\n",
            "Name: target, dtype: int64\n",
            "increase     1553\n",
            "decrease     1349\n",
            "no change      16\n",
            "Name: target, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-123-9fe87a8b200c>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'price_change'] = df['price'].pct_change()\n",
            "<ipython-input-123-9fe87a8b200c>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.dropna(inplace=True)\n",
            "<ipython-input-123-9fe87a8b200c>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'target'] = 'no change'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_target_to_dataframe(df, threshold=0.0001):\n",
        "    # Compute the percentage change from the current to the next day's price\n",
        "    df.loc[:, 'price_change'] = df['price'].pct_change()\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    # Define the target variable based on the price change\n",
        "    df.loc[:, 'target'] = 'no change'\n",
        "    df.loc[df['price_change'] > threshold, 'target'] = 'increase'\n",
        "    df.loc[df['price_change'] < -threshold, 'target'] = 'decrease'\n",
        "\n",
        "    print(df['target'].value_counts())\n",
        "\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "k7U9Vx27Zvrq"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_values(timestamp, *args):\n",
        "    import matplotlib\n",
        "\n",
        "    if len(args) % 2 != 0:\n",
        "        raise ValueError(\"Every feature should have a corresponding name\")\n",
        "\n",
        "    # Use a predefined style\n",
        "    plt.style.use('ggplot')\n",
        "\n",
        "    # Set figure size\n",
        "    fig, ax = plt.subplots(figsize=(12,6))\n",
        "\n",
        "    # Create a colormap that will generate colors\n",
        "    colormap = matplotlib.colormaps['tab10']\n",
        "\n",
        "    # Plot data with customized line for each feature\n",
        "    for i in range(0, len(args), 2):\n",
        "        feature_name = args[i]\n",
        "        feature_values = args[i+1]\n",
        "        color = colormap(i // 2 / (len(args)//2))\n",
        "        ax.plot(timestamp, feature_values, label=feature_name, color=color, linewidth=1)\n",
        "\n",
        "    # Set labels with improved readability\n",
        "    ax.set_xlabel('Date')\n",
        "    ax.yaxis.set_label_position(\"right\") # This line moves y label to the right\n",
        "    ax.set_ylabel('Feature Values')\n",
        "    ax.yaxis.tick_right() # This line moves y axis to the right\n",
        "    ax.set_title('Features over Time')\n",
        "\n",
        "    # Format the timestamps and set locator\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d')) # format as year-month-day\n",
        "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=3)) # display a label at the start of every 3rd month\n",
        "\n",
        "    # Rotate x-axis labels for better visibility\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    # Add a grid\n",
        "    ax.grid(True)\n",
        "\n",
        "    # Add legend\n",
        "    ax.legend()\n",
        "\n",
        "    # Show plot\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "t_897CNsF-zI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "def data_preparation_classifier(df, lookback, future, scale, test_size=0.1):\n",
        "    # Convert 'Date' column to datetime\n",
        "    date_train = pd.to_datetime(df.index)\n",
        "\n",
        "    target_column = 'target'  # assuming your target column is named 'target'\n",
        "\n",
        "    # Separate features and target\n",
        "    features = df.drop(target_column, axis=1)\n",
        "    target = df[[target_column]]\n",
        "\n",
        "    # Split data into training and testing before scaling\n",
        "    df_features_train, df_features_test, target_train, target_test = train_test_split(features, target, test_size=test_size, shuffle=False)\n",
        "\n",
        "    # Scale features\n",
        "    df_train_scaled = scale.fit_transform(df_features_train)\n",
        "    df_test_scaled = scale.transform(df_features_test)  # use the scaler fitted on the training data\n",
        "\n",
        "    # One-hot encode target variable\n",
        "    encoder = OneHotEncoder(sparse=False)\n",
        "    target_train_encoded = encoder.fit_transform(target_train)\n",
        "    target_test_encoded = encoder.transform(target_test)\n",
        "\n",
        "    # Create the feature and target arrays\n",
        "    X_train, y_train = [], []\n",
        "    for i in range(lookback, len(df_train_scaled)-future+1):\n",
        "        X_train.append(df_train_scaled[i-lookback:i, :])\n",
        "        y_train.append(target_train_encoded[i+future-1])\n",
        "\n",
        "    X_test, y_test = [], []\n",
        "    for i in range(lookback, len(df_test_scaled)-future+1):\n",
        "        X_test.append(df_test_scaled[i-lookback:i, :])\n",
        "        y_test.append(target_test_encoded[i+future-1])\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    X_train = np.array(X_train)\n",
        "    y_train = np.array(y_train)\n",
        "    X_test = np.array(X_test)\n",
        "    y_test = np.array(y_test)\n",
        "    print(f\"X_train shape: {X_train.shape}\")\n",
        "    print(f\"y_train shape: {y_train.shape}\")\n",
        "    print(f\"X_test shape: {X_test.shape}\")\n",
        "    print(f\"y_test shape: {y_test.shape}\")\n",
        "    return X_train, X_test, y_train, y_test, date_train, encoder\n",
        "\n"
      ],
      "metadata": {
        "id": "fCI_63bPGD5v"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm_classifier(X, y):\n",
        "    model_name=\"lstm_1_\"+str(int(time.time()))\n",
        "    model=Sequential(name=model_name)\n",
        "\n",
        "    model.add(Bidirectional(LSTM(units=256, return_sequences=True), input_shape=(X.shape[1], X.shape[2])))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Bidirectional(LSTM(units=128, return_sequences=False)))\n",
        "    model.add(Dense(25))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "    adam = optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=adam, metrics=['accuracy'])  # And this\n",
        "\n",
        "    model.fit(X, y, validation_split=0.1, epochs=50, batch_size=32)\n",
        "    return model"
      ],
      "metadata": {
        "id": "PeLd_pZ27Elz"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm_1(X, y):\n",
        "    model_name=\"lstm_1_\"+str(int(time.time()))\n",
        "    model=Sequential(name=model_name)\n",
        "\n",
        "    model.add(Bidirectional(LSTM(units=256, return_sequences=True), input_shape=(X.shape[1], X.shape[2])))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Bidirectional(LSTM(units=128, return_sequences=False)))\n",
        "    model.add(Dense(25))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    adam = optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss='mean_squared_error',optimizer=adam)\n",
        "\n",
        "    model.fit(X, y, validation_split=0.1, epochs=50, batch_size=32)\n",
        "    return model"
      ],
      "metadata": {
        "id": "gRCwAL02GEAw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm_2(X, y):\n",
        "    model_name=\"lstm_1_\"+str(int(time.time()))\n",
        "    model=Sequential(name=model_name)\n",
        "\n",
        "    model.add(LSTM(units=256, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(units=128, return_sequences=False))\n",
        "    model.add(Dense(25))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    adam = optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss='mean_squared_error',optimizer=adam)\n",
        "\n",
        "    model.fit(X, y, validation_split=0.1, epochs=50, batch_size=32)\n",
        "    return model"
      ],
      "metadata": {
        "id": "uAtl68TNGQc4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.regularizers import l2\n",
        "\n",
        "def lstm_3(X, y):\n",
        "    model_name=\"lstm_3_\"+str(int(time.time()))\n",
        "    model=Sequential(name=model_name)\n",
        "\n",
        "    model.add(LSTM(512, return_sequences=True, input_shape=(X.shape[1], X.shape[2]), kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(128, return_sequences=True, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(64, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(16, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "    model.add(Dense(3, activation='softmax'))  # Change this\n",
        "\n",
        "    adam = optimizers.Adam(learning_rate=0.01)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])  # And this\n",
        "\n",
        "    model.fit(X, y, validation_split=0.1, epochs=100, batch_size=32, verbose=1)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "0Vkm-g9wVbI7"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_classifier(df):\n",
        "    scale = MinMaxScaler(feature_range=(0,1))\n",
        "    X_train, X_test, y_train, y_test, date_train, encoder = data_preparation_classifier(df, 60, 1, scale)\n",
        "    print(y_train)\n",
        "\n",
        "    model = lstm_classifier(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "    predicted_classes_onehot = to_categorical(predicted_classes, num_classes=y_train.shape[1])\n",
        "\n",
        "\n",
        "    # Inverse transform the predicted classes back to original labels\n",
        "    predicted_labels = encoder.inverse_transform(predicted_classes_onehot)\n",
        "    print(predicted_labels)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(np.argmax(y_test, axis=1), predicted_classes)\n",
        "    print('Model Accuracy:', accuracy)"
      ],
      "metadata": {
        "id": "NYz02hBdGvzj"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_classifier(ta_df)\n",
        "predict_classifier(oc_df)\n",
        "predict_classifier(oc_ta_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uze0cl4B5KPK",
        "outputId": "8e82642b-ffd7-4dc8-a65b-9803bcca5ff9"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (2567, 60, 89)\n",
            "y_train shape: (2567, 3)\n",
            "X_test shape: (232, 60, 89)\n",
            "y_test shape: (232, 3)\n",
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Epoch 1/50\n",
            "73/73 [==============================] - 10s 35ms/step - loss: 0.7452 - accuracy: 0.5208 - val_loss: 0.7645 - val_accuracy: 0.4786\n",
            "Epoch 2/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.7208 - accuracy: 0.5281 - val_loss: 0.7438 - val_accuracy: 0.4786\n",
            "Epoch 3/50\n",
            "73/73 [==============================] - 1s 18ms/step - loss: 0.7215 - accuracy: 0.5377 - val_loss: 0.7452 - val_accuracy: 0.5136\n",
            "Epoch 4/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.7225 - accuracy: 0.5238 - val_loss: 0.7423 - val_accuracy: 0.5097\n",
            "Epoch 5/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.7187 - accuracy: 0.5398 - val_loss: 0.7477 - val_accuracy: 0.5136\n",
            "Epoch 6/50\n",
            "73/73 [==============================] - 2s 24ms/step - loss: 0.7157 - accuracy: 0.5290 - val_loss: 0.7422 - val_accuracy: 0.4786\n",
            "Epoch 7/50\n",
            "73/73 [==============================] - 2s 21ms/step - loss: 0.7129 - accuracy: 0.5502 - val_loss: 0.7387 - val_accuracy: 0.5331\n",
            "Epoch 8/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.7122 - accuracy: 0.5494 - val_loss: 0.7523 - val_accuracy: 0.4786\n",
            "Epoch 9/50\n",
            "73/73 [==============================] - 1s 16ms/step - loss: 0.7132 - accuracy: 0.5390 - val_loss: 0.7525 - val_accuracy: 0.4786\n",
            "Epoch 10/50\n",
            "73/73 [==============================] - 1s 18ms/step - loss: 0.7117 - accuracy: 0.5511 - val_loss: 0.7466 - val_accuracy: 0.4786\n",
            "Epoch 11/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.7148 - accuracy: 0.5506 - val_loss: 0.7755 - val_accuracy: 0.4786\n",
            "Epoch 12/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.7119 - accuracy: 0.5407 - val_loss: 0.7901 - val_accuracy: 0.4786\n",
            "Epoch 13/50\n",
            "73/73 [==============================] - 2s 25ms/step - loss: 0.7144 - accuracy: 0.5307 - val_loss: 0.7461 - val_accuracy: 0.5136\n",
            "Epoch 14/50\n",
            "73/73 [==============================] - 2s 24ms/step - loss: 0.7098 - accuracy: 0.5528 - val_loss: 0.7788 - val_accuracy: 0.4786\n",
            "Epoch 15/50\n",
            "73/73 [==============================] - 2s 24ms/step - loss: 0.7075 - accuracy: 0.5489 - val_loss: 0.7612 - val_accuracy: 0.4786\n",
            "Epoch 16/50\n",
            "73/73 [==============================] - 1s 16ms/step - loss: 0.7082 - accuracy: 0.5472 - val_loss: 0.7526 - val_accuracy: 0.4825\n",
            "Epoch 17/50\n",
            "73/73 [==============================] - 1s 18ms/step - loss: 0.7084 - accuracy: 0.5472 - val_loss: 0.7552 - val_accuracy: 0.4786\n",
            "Epoch 18/50\n",
            "73/73 [==============================] - 1s 16ms/step - loss: 0.7062 - accuracy: 0.5498 - val_loss: 0.7423 - val_accuracy: 0.5214\n",
            "Epoch 19/50\n",
            "73/73 [==============================] - 1s 16ms/step - loss: 0.7068 - accuracy: 0.5528 - val_loss: 0.7436 - val_accuracy: 0.5214\n",
            "Epoch 20/50\n",
            "73/73 [==============================] - 1s 16ms/step - loss: 0.7045 - accuracy: 0.5567 - val_loss: 0.7517 - val_accuracy: 0.4942\n",
            "Epoch 21/50\n",
            "73/73 [==============================] - 1s 16ms/step - loss: 0.7046 - accuracy: 0.5515 - val_loss: 0.7367 - val_accuracy: 0.5370\n",
            "Epoch 22/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.7022 - accuracy: 0.5719 - val_loss: 0.7355 - val_accuracy: 0.5642\n",
            "Epoch 23/50\n",
            "73/73 [==============================] - 1s 16ms/step - loss: 0.7041 - accuracy: 0.5545 - val_loss: 0.7545 - val_accuracy: 0.4825\n",
            "Epoch 24/50\n",
            "73/73 [==============================] - 2s 23ms/step - loss: 0.7012 - accuracy: 0.5693 - val_loss: 0.7607 - val_accuracy: 0.4864\n",
            "Epoch 25/50\n",
            "73/73 [==============================] - 2s 31ms/step - loss: 0.6966 - accuracy: 0.5771 - val_loss: 0.7517 - val_accuracy: 0.4903\n",
            "Epoch 26/50\n",
            "73/73 [==============================] - 2s 32ms/step - loss: 0.7038 - accuracy: 0.5714 - val_loss: 0.7504 - val_accuracy: 0.4864\n",
            "Epoch 27/50\n",
            "73/73 [==============================] - 1s 16ms/step - loss: 0.6949 - accuracy: 0.5775 - val_loss: 0.7645 - val_accuracy: 0.4825\n",
            "Epoch 28/50\n",
            "73/73 [==============================] - 1s 16ms/step - loss: 0.7016 - accuracy: 0.5680 - val_loss: 0.7510 - val_accuracy: 0.4864\n",
            "Epoch 29/50\n",
            "73/73 [==============================] - 1s 16ms/step - loss: 0.6985 - accuracy: 0.5701 - val_loss: 0.7676 - val_accuracy: 0.4786\n",
            "Epoch 30/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.6950 - accuracy: 0.5771 - val_loss: 0.7463 - val_accuracy: 0.5175\n",
            "Epoch 31/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.6899 - accuracy: 0.5762 - val_loss: 0.7435 - val_accuracy: 0.5331\n",
            "Epoch 32/50\n",
            "73/73 [==============================] - 2s 22ms/step - loss: 0.6931 - accuracy: 0.5736 - val_loss: 0.7476 - val_accuracy: 0.4786\n",
            "Epoch 33/50\n",
            "73/73 [==============================] - 2s 24ms/step - loss: 0.6820 - accuracy: 0.5892 - val_loss: 0.7427 - val_accuracy: 0.5447\n",
            "Epoch 34/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.6847 - accuracy: 0.5948 - val_loss: 0.8325 - val_accuracy: 0.4786\n",
            "Epoch 35/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.7092 - accuracy: 0.5615 - val_loss: 0.7507 - val_accuracy: 0.4786\n",
            "Epoch 36/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.7043 - accuracy: 0.5680 - val_loss: 0.7401 - val_accuracy: 0.5331\n",
            "Epoch 37/50\n",
            "73/73 [==============================] - 1s 16ms/step - loss: 0.6969 - accuracy: 0.5805 - val_loss: 0.7489 - val_accuracy: 0.5370\n",
            "Epoch 38/50\n",
            "73/73 [==============================] - 1s 16ms/step - loss: 0.6951 - accuracy: 0.5758 - val_loss: 0.7469 - val_accuracy: 0.5175\n",
            "Epoch 39/50\n",
            "73/73 [==============================] - 1s 18ms/step - loss: 0.6943 - accuracy: 0.5810 - val_loss: 0.7671 - val_accuracy: 0.4669\n",
            "Epoch 40/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.6874 - accuracy: 0.5970 - val_loss: 0.7654 - val_accuracy: 0.4747\n",
            "Epoch 41/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.6919 - accuracy: 0.5732 - val_loss: 0.7738 - val_accuracy: 0.5058\n",
            "Epoch 42/50\n",
            "73/73 [==============================] - 2s 23ms/step - loss: 0.6893 - accuracy: 0.5922 - val_loss: 0.7780 - val_accuracy: 0.5214\n",
            "Epoch 43/50\n",
            "73/73 [==============================] - 2s 21ms/step - loss: 0.6870 - accuracy: 0.5788 - val_loss: 0.7722 - val_accuracy: 0.4786\n",
            "Epoch 44/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.6839 - accuracy: 0.5853 - val_loss: 0.7575 - val_accuracy: 0.5097\n",
            "Epoch 45/50\n",
            "73/73 [==============================] - 1s 18ms/step - loss: 0.6900 - accuracy: 0.5714 - val_loss: 0.7580 - val_accuracy: 0.5058\n",
            "Epoch 46/50\n",
            "73/73 [==============================] - 1s 16ms/step - loss: 0.6782 - accuracy: 0.5939 - val_loss: 0.7562 - val_accuracy: 0.5136\n",
            "Epoch 47/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.6715 - accuracy: 0.6000 - val_loss: 0.7722 - val_accuracy: 0.4825\n",
            "Epoch 48/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.6669 - accuracy: 0.6273 - val_loss: 0.8132 - val_accuracy: 0.4825\n",
            "Epoch 49/50\n",
            "73/73 [==============================] - 1s 16ms/step - loss: 0.6587 - accuracy: 0.6208 - val_loss: 0.7953 - val_accuracy: 0.4903\n",
            "Epoch 50/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.6587 - accuracy: 0.6251 - val_loss: 0.7837 - val_accuracy: 0.4903\n",
            "8/8 [==============================] - 1s 7ms/step\n",
            "[['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['decrease']]\n",
            "Model Accuracy: 0.5172413793103449\n",
            "X_train shape: (2567, 60, 116)\n",
            "y_train shape: (2567, 3)\n",
            "X_test shape: (232, 60, 116)\n",
            "y_test shape: (232, 3)\n",
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "73/73 [==============================] - 11s 39ms/step - loss: 0.7480 - accuracy: 0.5234 - val_loss: 0.7420 - val_accuracy: 0.4786\n",
            "Epoch 2/50\n",
            "73/73 [==============================] - 2s 25ms/step - loss: 0.7218 - accuracy: 0.5199 - val_loss: 0.7629 - val_accuracy: 0.5136\n",
            "Epoch 3/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.7181 - accuracy: 0.5511 - val_loss: 0.7484 - val_accuracy: 0.5136\n",
            "Epoch 4/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.7164 - accuracy: 0.5364 - val_loss: 0.7387 - val_accuracy: 0.5136\n",
            "Epoch 5/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.7166 - accuracy: 0.5381 - val_loss: 0.7380 - val_accuracy: 0.4825\n",
            "Epoch 6/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.7100 - accuracy: 0.5407 - val_loss: 0.7445 - val_accuracy: 0.4825\n",
            "Epoch 7/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.7148 - accuracy: 0.5385 - val_loss: 0.7412 - val_accuracy: 0.4942\n",
            "Epoch 8/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.7147 - accuracy: 0.5554 - val_loss: 0.7399 - val_accuracy: 0.4825\n",
            "Epoch 9/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.7084 - accuracy: 0.5506 - val_loss: 0.7376 - val_accuracy: 0.4708\n",
            "Epoch 10/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.7035 - accuracy: 0.5654 - val_loss: 0.7670 - val_accuracy: 0.4786\n",
            "Epoch 11/50\n",
            "73/73 [==============================] - 2s 25ms/step - loss: 0.7071 - accuracy: 0.5545 - val_loss: 0.7407 - val_accuracy: 0.4669\n",
            "Epoch 12/50\n",
            "73/73 [==============================] - 1s 20ms/step - loss: 0.7049 - accuracy: 0.5498 - val_loss: 0.7474 - val_accuracy: 0.5058\n",
            "Epoch 13/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.7086 - accuracy: 0.5420 - val_loss: 0.7462 - val_accuracy: 0.5058\n",
            "Epoch 14/50\n",
            "73/73 [==============================] - 1s 18ms/step - loss: 0.7085 - accuracy: 0.5506 - val_loss: 0.7384 - val_accuracy: 0.4942\n",
            "Epoch 15/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.7102 - accuracy: 0.5476 - val_loss: 0.7407 - val_accuracy: 0.5019\n",
            "Epoch 16/50\n",
            "73/73 [==============================] - 1s 19ms/step - loss: 0.7046 - accuracy: 0.5532 - val_loss: 0.7438 - val_accuracy: 0.4942\n",
            "Epoch 17/50\n",
            "73/73 [==============================] - 1s 19ms/step - loss: 0.7011 - accuracy: 0.5688 - val_loss: 0.7399 - val_accuracy: 0.5019\n",
            "Epoch 18/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.7013 - accuracy: 0.5576 - val_loss: 0.7463 - val_accuracy: 0.5447\n",
            "Epoch 19/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.6980 - accuracy: 0.5576 - val_loss: 0.7519 - val_accuracy: 0.4708\n",
            "Epoch 20/50\n",
            "73/73 [==============================] - 2s 22ms/step - loss: 0.6963 - accuracy: 0.5589 - val_loss: 0.7518 - val_accuracy: 0.4747\n",
            "Epoch 21/50\n",
            "73/73 [==============================] - 2s 22ms/step - loss: 0.6965 - accuracy: 0.5810 - val_loss: 0.7509 - val_accuracy: 0.5019\n",
            "Epoch 22/50\n",
            "73/73 [==============================] - 2s 21ms/step - loss: 0.6953 - accuracy: 0.5753 - val_loss: 0.7493 - val_accuracy: 0.4903\n",
            "Epoch 23/50\n",
            "73/73 [==============================] - 2s 22ms/step - loss: 0.6947 - accuracy: 0.5714 - val_loss: 0.7903 - val_accuracy: 0.4825\n",
            "Epoch 24/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.6993 - accuracy: 0.5619 - val_loss: 0.7471 - val_accuracy: 0.5214\n",
            "Epoch 25/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.6907 - accuracy: 0.5597 - val_loss: 0.7610 - val_accuracy: 0.5370\n",
            "Epoch 26/50\n",
            "73/73 [==============================] - 1s 18ms/step - loss: 0.6909 - accuracy: 0.5905 - val_loss: 0.7548 - val_accuracy: 0.5019\n",
            "Epoch 27/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.6941 - accuracy: 0.5835 - val_loss: 0.7539 - val_accuracy: 0.5175\n",
            "Epoch 28/50\n",
            "73/73 [==============================] - 1s 16ms/step - loss: 0.6908 - accuracy: 0.5788 - val_loss: 0.7596 - val_accuracy: 0.5175\n",
            "Epoch 29/50\n",
            "73/73 [==============================] - 2s 23ms/step - loss: 0.6876 - accuracy: 0.5745 - val_loss: 0.7871 - val_accuracy: 0.4747\n",
            "Epoch 30/50\n",
            "73/73 [==============================] - 2s 21ms/step - loss: 0.6901 - accuracy: 0.5766 - val_loss: 0.7600 - val_accuracy: 0.5292\n",
            "Epoch 31/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.6833 - accuracy: 0.5939 - val_loss: 0.8117 - val_accuracy: 0.5019\n",
            "Epoch 32/50\n",
            "73/73 [==============================] - 1s 16ms/step - loss: 0.6847 - accuracy: 0.5814 - val_loss: 0.7629 - val_accuracy: 0.5214\n",
            "Epoch 33/50\n",
            "73/73 [==============================] - 1s 18ms/step - loss: 0.6868 - accuracy: 0.5874 - val_loss: 0.7875 - val_accuracy: 0.4786\n",
            "Epoch 34/50\n",
            "73/73 [==============================] - 1s 18ms/step - loss: 0.6856 - accuracy: 0.5831 - val_loss: 0.7644 - val_accuracy: 0.5097\n",
            "Epoch 35/50\n",
            "73/73 [==============================] - 1s 18ms/step - loss: 0.6806 - accuracy: 0.5866 - val_loss: 0.7638 - val_accuracy: 0.4630\n",
            "Epoch 36/50\n",
            "73/73 [==============================] - 1s 19ms/step - loss: 0.6765 - accuracy: 0.5961 - val_loss: 0.8221 - val_accuracy: 0.5097\n",
            "Epoch 37/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.6737 - accuracy: 0.5913 - val_loss: 0.7727 - val_accuracy: 0.4747\n",
            "Epoch 38/50\n",
            "73/73 [==============================] - 2s 21ms/step - loss: 0.6748 - accuracy: 0.6022 - val_loss: 0.7871 - val_accuracy: 0.4942\n",
            "Epoch 39/50\n",
            "73/73 [==============================] - 2s 25ms/step - loss: 0.6756 - accuracy: 0.6048 - val_loss: 0.7668 - val_accuracy: 0.5097\n",
            "Epoch 40/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.6686 - accuracy: 0.6030 - val_loss: 0.8188 - val_accuracy: 0.5058\n",
            "Epoch 41/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.6712 - accuracy: 0.6117 - val_loss: 0.8110 - val_accuracy: 0.5058\n",
            "Epoch 42/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.6741 - accuracy: 0.5996 - val_loss: 0.7755 - val_accuracy: 0.4708\n",
            "Epoch 43/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.6624 - accuracy: 0.6229 - val_loss: 0.7959 - val_accuracy: 0.4864\n",
            "Epoch 44/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.6685 - accuracy: 0.5961 - val_loss: 0.7875 - val_accuracy: 0.4708\n",
            "Epoch 45/50\n",
            "73/73 [==============================] - 1s 18ms/step - loss: 0.6579 - accuracy: 0.6134 - val_loss: 0.8241 - val_accuracy: 0.5058\n",
            "Epoch 46/50\n",
            "73/73 [==============================] - 1s 18ms/step - loss: 0.6655 - accuracy: 0.6199 - val_loss: 0.7991 - val_accuracy: 0.5409\n",
            "Epoch 47/50\n",
            "73/73 [==============================] - 1s 19ms/step - loss: 0.6576 - accuracy: 0.6173 - val_loss: 0.8054 - val_accuracy: 0.5136\n",
            "Epoch 48/50\n",
            "73/73 [==============================] - 2s 24ms/step - loss: 0.6529 - accuracy: 0.6139 - val_loss: 0.7880 - val_accuracy: 0.5214\n",
            "Epoch 49/50\n",
            "73/73 [==============================] - 2s 21ms/step - loss: 0.6534 - accuracy: 0.6087 - val_loss: 0.8134 - val_accuracy: 0.5214\n",
            "Epoch 50/50\n",
            "73/73 [==============================] - 1s 18ms/step - loss: 0.6493 - accuracy: 0.6229 - val_loss: 0.8339 - val_accuracy: 0.5214\n",
            "8/8 [==============================] - 1s 7ms/step\n",
            "[['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['increase']]\n",
            "Model Accuracy: 0.5301724137931034\n",
            "X_train shape: (2567, 60, 203)\n",
            "y_train shape: (2567, 3)\n",
            "X_test shape: (232, 60, 203)\n",
            "y_test shape: (232, 3)\n",
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "73/73 [==============================] - 12s 40ms/step - loss: 0.7473 - accuracy: 0.5199 - val_loss: 0.7436 - val_accuracy: 0.4786\n",
            "Epoch 2/50\n",
            "73/73 [==============================] - 1s 19ms/step - loss: 0.7223 - accuracy: 0.5398 - val_loss: 0.7658 - val_accuracy: 0.5136\n",
            "Epoch 3/50\n",
            "73/73 [==============================] - 1s 18ms/step - loss: 0.7191 - accuracy: 0.5372 - val_loss: 0.7427 - val_accuracy: 0.5136\n",
            "Epoch 4/50\n",
            "73/73 [==============================] - 1s 18ms/step - loss: 0.7142 - accuracy: 0.5550 - val_loss: 0.7448 - val_accuracy: 0.5136\n",
            "Epoch 5/50\n",
            "73/73 [==============================] - 1s 19ms/step - loss: 0.7133 - accuracy: 0.5489 - val_loss: 0.7419 - val_accuracy: 0.4747\n",
            "Epoch 6/50\n",
            "73/73 [==============================] - 1s 20ms/step - loss: 0.7135 - accuracy: 0.5416 - val_loss: 0.7419 - val_accuracy: 0.5136\n",
            "Epoch 7/50\n",
            "73/73 [==============================] - 2s 29ms/step - loss: 0.7127 - accuracy: 0.5442 - val_loss: 0.7342 - val_accuracy: 0.5292\n",
            "Epoch 8/50\n",
            "73/73 [==============================] - 2s 22ms/step - loss: 0.7085 - accuracy: 0.5532 - val_loss: 0.7377 - val_accuracy: 0.5331\n",
            "Epoch 9/50\n",
            "73/73 [==============================] - 1s 19ms/step - loss: 0.7111 - accuracy: 0.5446 - val_loss: 0.7485 - val_accuracy: 0.5136\n",
            "Epoch 10/50\n",
            "73/73 [==============================] - 1s 19ms/step - loss: 0.7073 - accuracy: 0.5411 - val_loss: 0.7392 - val_accuracy: 0.5058\n",
            "Epoch 11/50\n",
            "73/73 [==============================] - 1s 19ms/step - loss: 0.7068 - accuracy: 0.5481 - val_loss: 0.7347 - val_accuracy: 0.5097\n",
            "Epoch 12/50\n",
            "73/73 [==============================] - 1s 19ms/step - loss: 0.7064 - accuracy: 0.5593 - val_loss: 0.7405 - val_accuracy: 0.5370\n",
            "Epoch 13/50\n",
            "73/73 [==============================] - 1s 19ms/step - loss: 0.7029 - accuracy: 0.5623 - val_loss: 0.7702 - val_accuracy: 0.4786\n",
            "Epoch 14/50\n",
            "73/73 [==============================] - 1s 18ms/step - loss: 0.7021 - accuracy: 0.5619 - val_loss: 0.7605 - val_accuracy: 0.4786\n",
            "Epoch 15/50\n",
            "73/73 [==============================] - 2s 24ms/step - loss: 0.6979 - accuracy: 0.5645 - val_loss: 0.7435 - val_accuracy: 0.5370\n",
            "Epoch 16/50\n",
            "73/73 [==============================] - 2s 26ms/step - loss: 0.6987 - accuracy: 0.5740 - val_loss: 0.7601 - val_accuracy: 0.4786\n",
            "Epoch 17/50\n",
            "73/73 [==============================] - 1s 20ms/step - loss: 0.7004 - accuracy: 0.5628 - val_loss: 0.7479 - val_accuracy: 0.5486\n",
            "Epoch 18/50\n",
            "73/73 [==============================] - 1s 19ms/step - loss: 0.7015 - accuracy: 0.5714 - val_loss: 0.7449 - val_accuracy: 0.5136\n",
            "Epoch 19/50\n",
            "73/73 [==============================] - 1s 20ms/step - loss: 0.6993 - accuracy: 0.5818 - val_loss: 0.7424 - val_accuracy: 0.5175\n",
            "Epoch 20/50\n",
            "73/73 [==============================] - 1s 18ms/step - loss: 0.6928 - accuracy: 0.5896 - val_loss: 0.7495 - val_accuracy: 0.4864\n",
            "Epoch 21/50\n",
            "73/73 [==============================] - 1s 19ms/step - loss: 0.6922 - accuracy: 0.5740 - val_loss: 0.7452 - val_accuracy: 0.5136\n",
            "Epoch 22/50\n",
            "73/73 [==============================] - 1s 20ms/step - loss: 0.6891 - accuracy: 0.5900 - val_loss: 0.7604 - val_accuracy: 0.4942\n",
            "Epoch 23/50\n",
            "73/73 [==============================] - 1s 20ms/step - loss: 0.6940 - accuracy: 0.5684 - val_loss: 0.7493 - val_accuracy: 0.5136\n",
            "Epoch 24/50\n",
            "73/73 [==============================] - 2s 26ms/step - loss: 0.6858 - accuracy: 0.5801 - val_loss: 0.7477 - val_accuracy: 0.5175\n",
            "Epoch 25/50\n",
            "73/73 [==============================] - 1s 20ms/step - loss: 0.6887 - accuracy: 0.5810 - val_loss: 0.7406 - val_accuracy: 0.5214\n",
            "Epoch 26/50\n",
            "73/73 [==============================] - 1s 19ms/step - loss: 0.6807 - accuracy: 0.5931 - val_loss: 0.7841 - val_accuracy: 0.4747\n",
            "Epoch 27/50\n",
            "73/73 [==============================] - 1s 19ms/step - loss: 0.6867 - accuracy: 0.5896 - val_loss: 0.7467 - val_accuracy: 0.5175\n",
            "Epoch 28/50\n",
            "73/73 [==============================] - 1s 19ms/step - loss: 0.6723 - accuracy: 0.6117 - val_loss: 0.7889 - val_accuracy: 0.5097\n",
            "Epoch 29/50\n",
            "73/73 [==============================] - 1s 19ms/step - loss: 0.6752 - accuracy: 0.5948 - val_loss: 0.7551 - val_accuracy: 0.5019\n",
            "Epoch 30/50\n",
            "73/73 [==============================] - 1s 19ms/step - loss: 0.6780 - accuracy: 0.5926 - val_loss: 0.7578 - val_accuracy: 0.4981\n",
            "Epoch 31/50\n",
            "73/73 [==============================] - 1s 19ms/step - loss: 0.6702 - accuracy: 0.5996 - val_loss: 0.7604 - val_accuracy: 0.5409\n",
            "Epoch 32/50\n",
            "73/73 [==============================] - 2s 25ms/step - loss: 0.6631 - accuracy: 0.6104 - val_loss: 0.7549 - val_accuracy: 0.4981\n",
            "Epoch 33/50\n",
            "73/73 [==============================] - 2s 25ms/step - loss: 0.6630 - accuracy: 0.6186 - val_loss: 0.7772 - val_accuracy: 0.4864\n",
            "Epoch 34/50\n",
            "73/73 [==============================] - 1s 19ms/step - loss: 0.6655 - accuracy: 0.6152 - val_loss: 0.7546 - val_accuracy: 0.5331\n",
            "Epoch 35/50\n",
            "73/73 [==============================] - 1s 20ms/step - loss: 0.6547 - accuracy: 0.6139 - val_loss: 0.7791 - val_accuracy: 0.4903\n",
            "Epoch 36/50\n",
            "73/73 [==============================] - 1s 20ms/step - loss: 0.6540 - accuracy: 0.6199 - val_loss: 0.7629 - val_accuracy: 0.5370\n",
            "Epoch 37/50\n",
            "73/73 [==============================] - 1s 20ms/step - loss: 0.6540 - accuracy: 0.6134 - val_loss: 0.7740 - val_accuracy: 0.5175\n",
            "Epoch 38/50\n",
            "73/73 [==============================] - 1s 18ms/step - loss: 0.6444 - accuracy: 0.6346 - val_loss: 0.7876 - val_accuracy: 0.5214\n",
            "Epoch 39/50\n",
            "73/73 [==============================] - 1s 20ms/step - loss: 0.6405 - accuracy: 0.6381 - val_loss: 0.7653 - val_accuracy: 0.5058\n",
            "Epoch 40/50\n",
            "73/73 [==============================] - 1s 19ms/step - loss: 0.6383 - accuracy: 0.6364 - val_loss: 0.8432 - val_accuracy: 0.4942\n",
            "Epoch 41/50\n",
            "73/73 [==============================] - 2s 26ms/step - loss: 0.6419 - accuracy: 0.6316 - val_loss: 0.8080 - val_accuracy: 0.5097\n",
            "Epoch 42/50\n",
            "73/73 [==============================] - 2s 22ms/step - loss: 0.6338 - accuracy: 0.6615 - val_loss: 0.7949 - val_accuracy: 0.5058\n",
            "Epoch 43/50\n",
            "73/73 [==============================] - 1s 20ms/step - loss: 0.6144 - accuracy: 0.6654 - val_loss: 0.7937 - val_accuracy: 0.4942\n",
            "Epoch 44/50\n",
            "73/73 [==============================] - 1s 18ms/step - loss: 0.6134 - accuracy: 0.6641 - val_loss: 0.7911 - val_accuracy: 0.5097\n",
            "Epoch 45/50\n",
            "73/73 [==============================] - 1s 19ms/step - loss: 0.6071 - accuracy: 0.6753 - val_loss: 0.7601 - val_accuracy: 0.5214\n",
            "Epoch 46/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.5986 - accuracy: 0.6810 - val_loss: 0.7837 - val_accuracy: 0.5253\n",
            "Epoch 47/50\n",
            "73/73 [==============================] - 1s 17ms/step - loss: 0.5835 - accuracy: 0.6935 - val_loss: 0.8412 - val_accuracy: 0.5175\n",
            "Epoch 48/50\n",
            "73/73 [==============================] - 1s 18ms/step - loss: 0.5672 - accuracy: 0.7065 - val_loss: 0.8054 - val_accuracy: 0.4942\n",
            "Epoch 49/50\n",
            "73/73 [==============================] - 2s 22ms/step - loss: 0.5591 - accuracy: 0.7091 - val_loss: 0.8276 - val_accuracy: 0.5253\n",
            "Epoch 50/50\n",
            "73/73 [==============================] - 2s 30ms/step - loss: 0.5423 - accuracy: 0.7255 - val_loss: 0.7966 - val_accuracy: 0.5136\n",
            "8/8 [==============================] - 1s 9ms/step\n",
            "[['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['decrease']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']\n",
            " ['increase']]\n",
            "Model Accuracy: 0.45689655172413796\n"
          ]
        }
      ]
    }
  ]
}